(HeightAtDisappearance))^0.5)/(9.81),
TemporalErrorUnder1gAssumption = EstimatedTimeUnder1gAssumption-OccludedTimeOfTrajectory,
ControlTime = (TimeFallingBeforeOcclusion+OccludedTimeOfTrajectory)-FlightDuration/2,
ControlTime2 = EstimatedTimeUnder1gAssumption - OccludedTimeOfTrajectory)
#####Coincidence Timing: Add categories, exclude data, ...
response$OcclusionCategory <- "long"
response$OcclusionCategory[response$OccludedTimeOfTrajectory < 0.25] <- "short"
response$g.factor <- as.factor(response$g)
response$g_2 <- "-1g" #this will be -1g
response$g_2[response$g == 9.81] <- "1.0g"
response$g_2[response$g == 6.8670] <- "0.7g"
response$g_2[response$g == 8.3385] <- "0.85g"
response$g_2[response$g == 11.2815] <- "1.15g"
response$g_2[response$g == 12.7530] <- "1.3g"
response <- response %>%
group_by(id) %>%
mutate(MeanTemporalErrorPerID = mean(TemporalError))
#####Compare medians and stuff
response <- response %>%
group_by(g_2,Condition,LongOcclusion) %>%
mutate(Median_Temporal_Error = median(TemporalError),
Median_TemporalErrorUnder1gAssumption = median(TemporalErrorUnder1gAssumption)) ###This is the delay we measured in our system (SD = 0.001894s)
response <- response[!(response$id == "s09" & response$trial == 5 & response$block == 4), ] #exclude trials with odd behaviour due to system failure
response <- response[!(response$id == "s04" & response$trial == 1 & response$block == 3), ]
response <- response[!(response$id == "s10" & response$trial == 1 & response$block == 1), ]
response <- response[!(response$id == "s07" & response$trial == 1 & response$block == 3), ]
######Model prediction versus reality
response <- response %>%
group_by(id, Condition,g,LongOcclusion) %>%
mutate(Median_Error_Obs_ID = median(TemporalError),
TemporalErrorUnder1gAssumption_ID = median(TemporalErrorUnder1gAssumption[abs(TemporalError) < 0.5]))
#exclude trials with odd behaviour due to system failure
#####check for sequential effects in 1g/-1g condition
response$gLastTrial <- c(0,response$g_2[1:length(response$g_2)-1])
response$Sequential <- 0
response$Sequential[response$gLastTrial == response$g_2] <- 1
response <- response %>%
group_by(Condition, Sequential, g_2) %>%
mutate(Median_Sequential = median(TemporalError))
unique(response$Median_Sequential[response$g_2 == "1.0g" & response$Condition == "-1g" & response$Sequential == 0])
response = response %>%
group_by(Condition,g_2,id,LongOcclusion) %>%
mutate(Mean_Temporal_Error = mean(TemporalError),
Median_Temporal_Error = median(TemporalError))
t.test(unique(response$TemporalError[
response$LongOcclusion == 1 &
response$g_2 == "1.0g" &
response$Condition == "Different g"]))
sd(unique(response$Mean_Temporal_Error[
response$LongOcclusion == 1 &
response$g_2 == "1.0g" &
response$Condition == "Different g"]))
#Hypothesis II: coincidence timing error LMM
response$g_Category <- 6 #this will be -1g
response$g_Category[response$g == 9.81] <- 1
response$g_Category[response$g == 6.8670] <- 2
response$g_Category[response$g == 8.3385] <- 3
response$g_Category[response$g == 11.2815] <- 4
response$g_Category[response$g == 12.7530] <- 5
ggplot(response[response$Condition == "Different g" & response$LongOcclusion == 1,], aes(x = as.factor(vy), y = TemporalError, col = g.factor)) +
geom_violin() +
#################
######Lets get the SD of the gravity prior!
################
######We have the standard deviations and means for
######    timing (mean = 0, SD from data, SD = 0.11s)
######    distance to travel (estimate!)
######    velocity at disappearance (estimate!)#
######And want the SD of G
######We assume that everything is estimated accurately
#####How do Weber fractions translate into SDs again? STUFF I SHOULD KNOW! #ups
#This is the time modelled with uncertainty (GET MORE ACCURATE SDs!!!
#How to translate weber fractions from percentage into SDs?)
#Answer: its the SD of that normal distribution which gives 0.75 for mean +/- Weber Fraction
#probably have to repeat this like a 1000 times?
#there are different sources of variability: not only g, but also the last seen velocity,
#and the observed distance, BUT ALSO MAYBE FROM THE RESPONSE. What about the "integration" mechanism????
#also, we might wanna limit this analysis to the long trials????
#Weber fractions for velocities are like 5%, but its harder to extract the vertical velocity component from parabolic motion, so lets go with 10%?
#https://www.sciencedirect.com/science/article/pii/004269898190095X
#... weber fraction of 10% corresponds to:
pnorm(1.1,1,0.148)
#an SD of 0.148, more or less
#for lengths it's: https://pdfs.semanticscholar.org/c529/aa57cc49bb0fee25f695869312a876b3ca47.pdf
#3-5% in fronto-parallel plane. However, they have pretty good reference and stuff, which are not present in our experiment
#in harder conditions, it's up to ~22%
#probably hard to find papers that cover exactly this ... lets go with 20%. Weber fraction of 20% corresponds to:
pnorm(1.05,1,0.15)
#an SD of about 0.15
n_Iterations = 2
SD_Gravity = 0.2
#motor error SD maybe around 30ms? https://jshd.pubs.asha.org/doi/full/10.1044/1092-4388%282003/012%29?casa_token=UAw_ubXyPlkAAAAA%3A9pfFHwevN336lmB1coLASAPwUqNFwn2W6Tes53k6JTM18xHlHnj4tGZNcF77Hwr_xsXCi3Vynxay&
#could be much lower, 10ms here: http://www.haskins.yale.edu/Reprints/HL1268.pdf
#interesting: motor error should be independent of length of prediction, f. e., while perceptual errors should increase with increased time window of prediction.
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.3,1,0.295)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.3,1,0.4)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.3,1,0.42)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.3,1,0.45)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.3,1,0.44)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.3,1,0.436)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.3,1,0.436)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.3,1,0.439)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.3,1,0.44)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.3,1,0.441)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.3,1,0.442)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.3,1,0.443)
GetSDMatchForMotorNoise = function(MotorNoiseSD,n_Iterations){
b = c()
for (i in 1:n_Iterations){
response = response %>%
mutate(SD_Factor_G = abs(rnorm(length(g),1,0.443)),
SD_Factor_VY = abs(rnorm(length(g),1,0.148)),
SD_Factor_Distance = abs(rnorm(length(g),1,0.15)),
Response_Variability = abs(rnorm(length(g),0,MotorNoiseSD)),
Mean_G = case_when(
LongOcclusion == 1 & vy == 4.5 ~ 0.82*9.81,
LongOcclusion == 0 & vy == 4.5 ~ 0.42*9.81,
LongOcclusion == 1 & vy == 6 ~ 0.92*9.81,
LongOcclusion == 0 & vy == 6 ~ 0.61*9.81
),
Perceived_G = Mean_G*SD_Factor_G,
Perceived_VY = abs(LastObserved_vy)*SD_Factor_VY,
Perceived_Distance = abs(HeightAtDisappearance)*SD_Factor_Distance)
response = response %>%
mutate(TemporalEstimateWithUncertainty = (-Perceived_VY +
(Perceived_VY^2 +
2*Perceived_G*Perceived_Distance)^0.5)/
Perceived_G,
TemporalEstimateWithUncertainty_AndResponseSD = TemporalEstimateWithUncertainty + Response_Variability)
ggplot(response[response$Condition == "-1g" & response$LongOcclusion == 1 ,], aes(as.factor(g),TemporalEstimateWithUncertainty_AndResponseSD-OccludedTimeOfTrajectory)) +
geom_violin()
#Here I get the SD of the participants timing - modelled responses and get actual responses
response = response %>%
group_by(g,vy,LongOcclusion,Condition) %>%
mutate(SD_per_TTC_Modelled = sd(TemporalEstimateWithUncertainty_AndResponseSD-OccludedTimeOfTrajectory,na.rm = TRUE),
SD_per_TTC_Real = sd(TemporalError,na.rm = TRUE),
Error_Per_TTC = (SD_per_TTC_Real-SD_per_TTC_Modelled)^2)
a = unique(response$Error_Per_TTC[response$Condition == "-1g"  & response$g == -9.81])
b = c(b,mean(a))
if (i==n_Iterations){
print("Round done")
print(MotorNoiseSD)
print(mean(b))}
}
mean(b)
}
Tentative_SD_Motor = seq(0,0.2,0.01)
error = c()
for (i in 1:length(Tentative_SD_Motor)){
f = GetSDMatchForMotorNoise(Tentative_SD_Motor[i],500)
error = c(error,f)
}
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.1,1,0.443)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.1,1,0.165)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.1,1,0.18)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.1,1,0.145)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.1,1,0.146)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.1,1,0.148)
response$G_Represented
response = response %>%
group_by(Condition,id,vy,LongOcclusion, g) %>%
mutate(MedianError = median(TemporalError),
MeanError = mean(TemporalError),
SDError = sd(TemporalError))
response$CenteredError = response$TemporalError-response$MedianError
response$AbsError = abs(response$CenteredError)
mean(response$SDError[response$g == 9.81 & response$LongOcclusion == 1])
mean(response$SDError[response$g == -9.81  & response$LongOcclusion == 1])
mod1 = lmer(
AbsError ~ as.factor(g) + (1 | LongOcclusion) + ( 1 | id) + (1 | vy),
data = response[response$Condition == "-1g",])
mod2 = lmer(
AbsError ~ (1 | LongOcclusion) + (1 | id) + (1 | vy),
data = response[response$Condition == "-1g",])
summary(mod1)
coef(mod1)
anova(mod1,mod2)
response = response %>%
group_by(id,vy,Condition,LongOcclusion) %>%
mutate(SD_Ratio = sd(TemporalError[g == 9.81])/sd(TemporalError[g == -9.81]))
SD_Ratios = response %>%
select(id,vy,LongOcclusion,id,SD_Ratio) %>%
distinct()
SD_Ratios = SD_Ratios[complete.cases(SD_Ratios),]
mean(SD_Ratios$SD_Ratio)
####What to do with this? There is an added 12% benefit in terms of precision for gravity concordant motion.
####That doesnt seem like an awful lot. Maybe it is partially activated?
####Can the lack of error for -1g give an indication of how much* the gravity model was activated?
response = response %>%
mutate(G_Represented = ((abs(HeightAtDisappearance)-abs(LastObserved_vy)*(OccludedTimeOfTrajectory+TemporalError))*2)/
(OccludedTimeOfTrajectory+TemporalError)^2) %>%
group_by(Condition,id,LongOcclusion,vy) %>%
mutate(Ratio_Accuracy = mean(G_Represented[g == -9.81 & G_Represented < 100])/mean(G_Represented[g == 9.81 &  G_Represented < 100]))
response$G_Represented
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.1,1,0.148)
GetSDMatchForMotorNoise = function(MotorNoiseSD,n_Iterations){
b = c()
for (i in 1:n_Iterations){
response = response %>%
mutate(SD_Factor_G = abs(rnorm(length(g),1,0.148)),
SD_Factor_VY = abs(rnorm(length(g),1,0.148)),
SD_Factor_Distance = abs(rnorm(length(g),1,0.15)),
Response_Variability = abs(rnorm(length(g),0,MotorNoiseSD)),
Mean_G = case_when(
LongOcclusion == 1 & vy == 4.5 ~ 0.82*9.81,
LongOcclusion == 0 & vy == 4.5 ~ 0.42*9.81,
LongOcclusion == 1 & vy == 6 ~ 0.92*9.81,
LongOcclusion == 0 & vy == 6 ~ 0.61*9.81
),
Perceived_G = Mean_G*SD_Factor_G,
Perceived_VY = abs(LastObserved_vy)*SD_Factor_VY,
Perceived_Distance = abs(HeightAtDisappearance)*SD_Factor_Distance)
response = response %>%
mutate(TemporalEstimateWithUncertainty = (-Perceived_VY +
(Perceived_VY^2 +
2*Perceived_G*Perceived_Distance)^0.5)/
Perceived_G,
TemporalEstimateWithUncertainty_AndResponseSD = TemporalEstimateWithUncertainty + Response_Variability)
ggplot(response[response$Condition == "-1g" & response$LongOcclusion == 1 ,], aes(as.factor(g),TemporalEstimateWithUncertainty_AndResponseSD-OccludedTimeOfTrajectory)) +
geom_violin()
#Here I get the SD of the participants timing - modelled responses and get actual responses
response = response %>%
group_by(g,vy,LongOcclusion,Condition) %>%
mutate(SD_per_TTC_Modelled = sd(TemporalEstimateWithUncertainty_AndResponseSD-OccludedTimeOfTrajectory,na.rm = TRUE),
SD_per_TTC_Real = sd(TemporalError,na.rm = TRUE),
Error_Per_TTC = (SD_per_TTC_Real-SD_per_TTC_Modelled)^2)
a = unique(response$Error_Per_TTC[response$Condition == "-1g"  & response$g == -9.81])
b = c(b,mean(a))
if (i==n_Iterations){
print("Round done")
print(MotorNoiseSD)
print(mean(b))}
}
mean(b)
}
Tentative_SD_Motor = seq(0,0.2,0.01)
error = c()
for (i in 1:length(Tentative_SD_Motor)){
f = GetSDMatchForMotorNoise(Tentative_SD_Motor[i],500)
error = c(error,f)
}
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.15,1,0.148)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.15,1,0.2)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.15,1,0.21)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.15,1,0.22)
#####Weber fractions of maybe like 20% for arbitrary gravities and accelerations (our 2018 paper, + 1/2 because we maybe used temporal information)
pnorm(1.15,1,0.222)
GetSDMatchForMotorNoise = function(MotorNoiseSD,n_Iterations){
b = c()
for (i in 1:n_Iterations){
response = response %>%
mutate(SD_Factor_G = abs(rnorm(length(g),1,0.222)),
SD_Factor_VY = abs(rnorm(length(g),1,0.148)),
SD_Factor_Distance = abs(rnorm(length(g),1,0.15)),
Response_Variability = abs(rnorm(length(g),0,MotorNoiseSD)),
Mean_G = case_when(
LongOcclusion == 1 & vy == 4.5 ~ 0.82*9.81,
LongOcclusion == 0 & vy == 4.5 ~ 0.42*9.81,
LongOcclusion == 1 & vy == 6 ~ 0.92*9.81,
LongOcclusion == 0 & vy == 6 ~ 0.61*9.81
),
Perceived_G = Mean_G*SD_Factor_G,
Perceived_VY = abs(LastObserved_vy)*SD_Factor_VY,
Perceived_Distance = abs(HeightAtDisappearance)*SD_Factor_Distance)
response = response %>%
mutate(TemporalEstimateWithUncertainty = (-Perceived_VY +
(Perceived_VY^2 +
2*Perceived_G*Perceived_Distance)^0.5)/
Perceived_G,
TemporalEstimateWithUncertainty_AndResponseSD = TemporalEstimateWithUncertainty + Response_Variability)
ggplot(response[response$Condition == "-1g" & response$LongOcclusion == 1 ,], aes(as.factor(g),TemporalEstimateWithUncertainty_AndResponseSD-OccludedTimeOfTrajectory)) +
geom_violin()
#Here I get the SD of the participants timing - modelled responses and get actual responses
response = response %>%
group_by(g,vy,LongOcclusion,Condition) %>%
mutate(SD_per_TTC_Modelled = sd(TemporalEstimateWithUncertainty_AndResponseSD-OccludedTimeOfTrajectory,na.rm = TRUE),
SD_per_TTC_Real = sd(TemporalError,na.rm = TRUE),
Error_Per_TTC = (SD_per_TTC_Real-SD_per_TTC_Modelled)^2)
a = unique(response$Error_Per_TTC[response$Condition == "-1g"  & response$g == -9.81])
b = c(b,mean(a))
if (i==n_Iterations){
print("Round done")
print(MotorNoiseSD)
print(mean(b))}
}
mean(b)
}
Tentative_SD_Motor = seq(0,0.2,0.01)
error = c()
for (i in 1:length(Tentative_SD_Motor)){
f = GetSDMatchForMotorNoise(Tentative_SD_Motor[i],500)
error = c(error,f)
}
plot(Tentative_SD_Motor,error)
GetSDMatchForG = function(SD_Gravity,n_Iterations){
b = c()
for (i in 1:n_Iterations){
response = response %>%
mutate(SD_Factor_G = abs(rnorm(length(g),1,SD_Gravity)),
SD_Factor_VY = abs(rnorm(length(g),1,0.148)),
SD_Factor_Distance = abs(rnorm(length(g),1,0.15)),
Response_Variability = abs(rnorm(length(g),0,0.16)),
Perceived_G = 9.81*SD_Factor_G,
Perceived_VY = LastObserved_vy*SD_Factor_VY,
Perceived_Distance = HeightAtDisappearance*SD_Factor_Distance)
response = response %>%
mutate(TemporalEstimateWithUncertainty = (-Perceived_VY +
(Perceived_VY^2 +
2*Perceived_G*Perceived_Distance)^0.5)/
Perceived_G,
TemporalEstimateWithUncertainty_AndResponseSD = TemporalEstimateWithUncertainty + Response_Variability)
#Here I get the SD of the participants timing - modelled responses and get actual responses
response = response %>%
group_by(g,vy,LongOcclusion,Condition) %>%
mutate(SD_per_TTC_Modelled = sd(TemporalEstimateWithUncertainty_AndResponseSD-OccludedTimeOfTrajectory,na.rm = TRUE),
SD_per_TTC_Real = sd(TemporalError,na.rm = TRUE),
Error_Per_TTC = (SD_per_TTC_Real-SD_per_TTC_Modelled)^2)
a = unique(response$Error_Per_TTC[response$LongOcclusion == 1 & response$Condition != "-1g"])
b = c(b,mean(a))
if (i==n_Iterations){
print("Round done")
print(SD_Gravity)
print(mean(b))
}
}
mean(b)
}
#Optimize over this function to get best SD fit for g
Optimization = optimize(GetSDMatchForG, c(0.18,0.22), n_Iterations = 500, maximum = FALSE, lower = 0.18, upper = 0.22, tol = 0.01)
Optimization
ggplot(PSEsJNDs[PSEsJNDs$parn == "p1",], aes(Congruent2,par, fill = Congruent2)) +
geom_bar(stat="identity",color="black") +
facet_grid(id~velH) +
ylab(label = "PSEs (m/s)") +
xlab(label = "") +
ggtitle(label = "PSE") +
scale_x_discrete(labels = c('incongruent','no motion','congruent')) +
theme(legend.position = "none")
mean(PSEsJNDs$par[PSEsJNDs$Congruent == "1motion"])
PSEsJNDs$par[PSEsJNDs$Congruent == "1motion"]
mean(PSEsJNDs$par[PSEsJNDs$Congruent == "1no motion"])
mean(PSEsJNDs$par[PSEsJNDs$Congruent == "1no motion" & PSEsJNDs$parn == "p1"])
mean(PSEsJNDs$par[PSEsJNDs$Congruent == "1no motion" & PSEsJNDs$parn == "p1"])
mean(PSEsJNDs$par[PSEsJNDs$Congruent == "1no motion" & PSEsJNDs$parn == "p1"])
mean(PSEsJNDs$par[PSEsJNDs$Congruent == "congruent" & PSEsJNDs$parn == "p1"])
mean(PSEsJNDs$par[PSEsJNDs$Congruent == "incongruent" & PSEsJNDs$parn == "p1"])
PSEsJNDs = PSEsJNDs %>%
group_by(Congruent, parn) %>%
mutate(mean_PSE = mean(par),
SD_PSE = sd(par),
n_PSE = length(par),
SE_PSE = SD_PSE/(n_PSE)^0.5)
PSEsJNDs = PSEsJNDs %>%
group_by(Congruent, parn) %>%
mutate(mean = mean(par),
SD = sd(par),
n = length(par),
SE = SD_PSE/(n_PSE)^0.5)
ggplot(PSEsJNDs[PSEsJNDs$parn == "p1",], aes(Congruent2,par, fill = Congruent2)) +
geom_bar(stat="identity",color="black") +
geom_errorbar(aes(ymin=mean-SE, ymax=mean+SE),
size=.3,    # Thinner lines
width=.3,
position=position_dodge(.9)) +
ylab(label = "PSEs (m/s)") +
xlab(label = "") +
ggtitle(label = "PSE") +
scale_x_discrete(labels = c('incongruent','no motion','congruent')) +
theme(legend.position = "none")
ggplot(PSEsJNDs[PSEsJNDs$parn == "p1",], aes(Congruent2,mean, fill = Congruent2)) +
geom_bar(stat="identity",color="black") +
geom_errorbar(aes(ymin=mean-SE, ymax=mean+SE),
size=.3,    # Thinner lines
width=.3,
position=position_dodge(.9)) +
ylab(label = "PSEs (m/s)") +
xlab(label = "") +
ggtitle(label = "PSE") +
scale_x_discrete(labels = c('incongruent','no motion','congruent')) +
theme(legend.position = "none")
ggplot(PSEsJNDs[PSEsJNDs$parn == "p2",], aes(Congruent2,mean, fill = Congruent2)) +
geom_bar(stat="identity",color="black") +
geom_errorbar(aes(ymin=mean-SE, ymax=mean+SE),
size=.3,    # Thinner lines
width=.3,
position=position_dodge(.9)) +
ylab(label = "SD (m/s)") +
xlab(label = "") +
ggtitle(label = "Thresholds") +
scale_x_discrete(labels = c('incongruent','no motion','congruent')) +
theme(legend.position = "none")
ggplot(PSEsJNDs[PSEsJNDs$parn == "p1",], aes(Congruent2,mean, fill = Congruent2)) +
geom_bar(stat="identity",color="black") +
geom_errorbar(aes(ymin=mean-SE, ymax=mean+SE),
size=.3,    # Thinner lines
width=.3,
position=position_dodge(.9)) +
ylab(label = "PSEs (m/s)") +
xlab(label = "") +
ggtitle(label = "PSE") +
scale_x_discrete(labels = c('incongruent','no motion','congruent')) +
theme(legend.position = "none")
ggplot(PSEsJNDs[PSEsJNDs$parn == "p1" & PSEsJNDs$velH == 6.6 & PSEsJNDs$id == "Laurence2",], aes(Congruent2,mean, fill = Congruent2)) +
geom_bar(stat="identity",color="black") +
geom_errorbar(aes(ymin=mean-SE, ymax=mean+SE),
size=.3,    # Thinner lines
width=.3,
position=position_dodge(.9)) +
ylab(label = "PSEs (m/s)") +
xlab(label = "") +
ggtitle(label = "PSE") +
scale_x_discrete(labels = c('incongruent','no motion','congruent')) +
theme(legend.position = "none")
ggplot(a[a$id %in% c("Meaghan", "Bjorn2", "Laurence2", "John", "Abi", "Bob"),], aes ( x = Difference, y = Pest_Bigger, col = as.factor(Congruent))) +
binomial_smooth() +
facet_grid(id~velH)
anova(mod1,mod2)
summary(mod1)
coef(mod1)
summary(mod1)
anova(mod1,mod2)
mod1 = glmer(cbind(Yes, Total - Yes) ~ Congruent + (Difference | id) + (Difference | velH),
family = binomial(link = "probit"),
data = Data_GLM[Data_GLM$id %in% c("Meaghan", "Bjorn2", "Abi", "John", "Bob", "Laurence2"),])
mod2 = glmer(cbind(Yes, Total - Yes) ~ (Difference | id)  + (Difference | velH),
family = binomial(link = "probit"),
data = Data_GLM[Data_GLM$id %in% c("Meaghan", "Bjorn2", "Abi", "John", "Bob", "Laurence2"),])
summary(mod1)
coef(mod1)
summary(mod1)
summary(mod1)
coef(mod1)
anova(mod1,mod2)
summary(mod3)
anova(mod4,mod3)
mod3 = glmer(cbind(Yes, Total - Yes) ~ Congruent*Difference + (Difference | id) + (Difference | velH),
family = binomial(link = "probit"),
data = Data_GLM[Data_GLM$id %in% c("Meaghan", "Bjorn2", "Abi", "John", "Bob", "Laurence2"),])
mod4 = glmer(cbind(Yes, Total - Yes) ~ Congruent + Difference + (Difference | id)  + (Difference | velH),
family = binomial(link = "probit"),
data = Data_GLM[Data_GLM$id %in% c("Meaghan", "Bjorn2", "Abi", "John", "Bob", "Laurence2"),])
ggplot(PSEsJNDs[PSEsJNDs$parn == "p2",], aes(Congruent2,mean, fill = Congruent2)) +
geom_bar(stat="identity",color="black") +
geom_errorbar(aes(ymin=mean-SE, ymax=mean+SE),
size=.3,    # Thinner lines
width=.3,
position=position_dodge(.9)) +
ylab(label = "SD (m/s)") +
xlab(label = "") +
ggtitle(label = "Thresholds") +
scale_x_discrete(labels = c('incongruent','no motion','congruent')) +
theme(legend.position = "none")
ggplot(PSEsJNDs[PSEsJNDs$parn == "p2",], aes(Congruent2,par, fill = Congruent2)) +
geom_bar(stat="identity",color="black") +
facet_grid(id~velH) +
ylab(label = "SD (m/s)") +
xlab(label = "") +
ggtitle(label = "Thresholds") +
scale_x_discrete(labels = c('incongruent','no motion','congruent')) +
theme(legend.position = "none")
mod1 = glmer(cbind(Yes, Total - Yes) ~ Congruent + (Difference | id) + (Difference | velH),
family = binomial(link = "probit"),
data = Data_GLM[Data_GLM$id %in% c("Meaghan", "Bjorn2", "Abi", "John", "Bob"),])
mod2 = glmer(cbind(Yes, Total - Yes) ~ (Difference | id)  + (Difference | velH),
family = binomial(link = "probit"),
data = Data_GLM[Data_GLM$id %in% c("Meaghan", "Bjorn2", "Abi", "John", "Bob"),])
mod3 = glmer(cbind(Yes, Total - Yes) ~ Congruent*Difference + (Difference | id) + (Difference | velH),
family = binomial(link = "probit"),
data = Data_GLM[Data_GLM$id %in% c("Meaghan", "Bjorn2", "Abi", "John", "Bob"),])
mod4 = glmer(cbind(Yes, Total - Yes) ~ Congruent + Difference + (Difference | id)  + (Difference | velH),
family = binomial(link = "probit"),
data = Data_GLM[Data_GLM$id %in% c("Meaghan", "Bjorn2", "Abi", "John", "Bob"),])
summary(mod1)
coef(mod1)
anova(mod1,mod2)
summary(mod3)
anova(mod4,mod3)
summary(mod1)
coef(mod1)
anova(mod1,mod2)
summary(mod3)
anova(mod4,mod3)
summary(mod1)
summary(mod1)
coef(mod1)
anova(mod1,mod2)
summary(mod3)
anova(mod4,mod3)
coef(mod1)
